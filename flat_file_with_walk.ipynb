{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0939cf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def extract_float(s):\n",
    "    # This regex pattern looks for any sequence of digits (\\d+), optionally followed by\n",
    "    # a decimal point and more digits (\\.\\d+)? The entire pattern is wrapped in parentheses\n",
    "    # to capture the match as a group.\n",
    "    match = re.search(r'(\\d+(\\.\\d+)?)', s)\n",
    "    if match:\n",
    "        return float(match.group(0))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def flatten_dict(d, parent_key='', sep='.'):\n",
    "    \"\"\"\n",
    "    Recursively flattens a nested dictionary and concatenates keys.\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "def read_yaml_files(directory):\n",
    "    data = []\n",
    "    unique_keys = set()\n",
    "    # Walk through all directories and subdirectories\n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.yaml') or filename.endswith('.yml'):\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                with open(filepath, 'r') as file:\n",
    "                    # Load and flatten the YAML file\n",
    "                    yaml_data = yaml.safe_load(file)\n",
    "                    flattened_data = flatten_dict(yaml_data)\n",
    "                    data.append(flattened_data)\n",
    "                    # Update unique keys set\n",
    "                    unique_keys.update(flattened_data.keys())\n",
    "    return data, unique_keys\n",
    "\n",
    "def write_to_flat_file(data, unique_keys, output_file):\n",
    "    with open(output_file, 'w') as file:\n",
    "        # Write the header\n",
    "        headers = list(unique_keys)\n",
    "        headers.sort()  # Optionally sort the headers for consistent ordering\n",
    "        file.write('\\t'.join(headers) + '\\n')\n",
    "        # Write the data\n",
    "        for item in data:\n",
    "            row = []\n",
    "            for key in headers:\n",
    "                row.append(str(item.get(key, \"\")))\n",
    "            file.write('\\t'.join(row) + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19885132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_float(s):\n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def add_best_acc_to_file(input_file, output_file, directory_prefix):\n",
    "    # Load the tab-delimited file into a DataFrame\n",
    "    df = pd.read_csv(input_file, delimiter='\\t')\n",
    "    \n",
    "    # Ensure the EXPERIMENT.NAME column exists\n",
    "    if 'EXPERIMENT.NAME' not in df.columns:\n",
    "        raise ValueError(\"EXPERIMENT.NAME column not found in the input file.\")\n",
    "    \n",
    "    # Initialize the BEST_ACC column with NaNs\n",
    "    df['BEST_ACC'] = float('nan')\n",
    "    \n",
    "    # Create a mapping of experiment names to best_acc values\n",
    "    experiment_acc = {}\n",
    "\n",
    "    # Search through all levels of the directory\n",
    "    for root, dirs, files in os.walk(directory_prefix):\n",
    "        if 'worklog.txt' in files:\n",
    "            worklog_path = os.path.join(root, 'worklog.txt')\n",
    "            experiment_name = os.path.basename(root)  # Assumes the experiment name is the folder name\n",
    "            \n",
    "            try:\n",
    "                with open(worklog_path, 'r') as worklog_file:\n",
    "                    for line in worklog_file:\n",
    "                        if line.startswith('best_acc'):\n",
    "                            best_acc_value = extract_float(line.split()[-1])\n",
    "                            if best_acc_value is not None:\n",
    "                                experiment_acc[experiment_name] = best_acc_value\n",
    "                                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {worklog_path}: {e}\")\n",
    "    \n",
    "    # Update the DataFrame with best_acc values found\n",
    "    for index, row in df.iterrows():\n",
    "        experiment_name = str(row['EXPERIMENT.NAME'])\n",
    "        if experiment_name in experiment_acc:\n",
    "            df.at[index, 'BEST_ACC'] = experiment_acc[experiment_name]\n",
    "    \n",
    "    # Save the updated DataFrame to a new tab-delimited file\n",
    "    df.to_csv(output_file, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d28c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory in the next cell points to the yamls. \n",
    "#and directory_prefix in the next points to the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443fabbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory = '/projectnb/textconv/distill/mdistiller/configs/cifar100/_bldmse/r328r84/' #mess with this to limit files.  this does all.\n",
    "#directory = '/projectnb/textconv/distill/mdistiller/configs/cifar100/_sldmse/r56r20/' \n",
    "#directory = '/projectnb/textconv/distill/mdistiller/configs/cifar100/_bldmsep/'\n",
    "#directory = '/projectnb/textconv/distill/mdistiller/configs/cifar100/_bldcd/'\n",
    "#directory = '/projectnb/textconv/distill/mdistiller/configs/cifar100/_bldcdp/'\n",
    "#directory = '/projectnb/textconv/distill/mdistiller/configs/cifar100/_bldcdpmp/'\n",
    "#directory = '/projectnb/textconv/distill/mdistiller/configs/cifar100/_bldcd2p/'\n",
    "directory = '/projectnb/textconv/distill/mdistiller/configs/cifar100/'\n",
    "\n",
    "output_file = 'sample_out_w.tsv'\n",
    "\n",
    "# Process the YAML files\n",
    "data, unique_keys = read_yaml_files(directory)\n",
    "\n",
    "# Write the collected data to a flat file\n",
    "write_to_flat_file(data, unique_keys, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "340643e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'sample_out_w.tsv'  # The path to your tab-delimited flat file\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Format the date and time in a way that is safe for filenames\n",
    "filename_format = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "parts = directory.split('/')\n",
    "mdistiller_index = parts.index('mdistiller')\n",
    "\n",
    "# Take everything after 'mdistiller' and join it with underscores\n",
    "direx = '_'.join(parts[mdistiller_index+1:])\n",
    "output_file = f'{direx}_{filename_format}.tsv'  # The path for the output file with the BEST_ACC column\n",
    "directory_prefix = '/projectnb/textconv/distill/mdistiller/output/'  # The prefix to the directory containing experiment folders\n",
    "#directory_prefix = '/projectnb/textconv/distill/mdistiller/output/imagenet_sldmse'\n",
    "# Call the function with the specified paths\n",
    "add_best_acc_to_file(input_file, output_file, directory_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43320084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
